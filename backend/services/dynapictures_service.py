#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Service de g√©n√©ration d'images avec Stable Diffusion pour Le Mixologue Augment√©

G√®re la g√©n√©ration d'images de cocktails en utilisant Stable Diffusion v1.5
avec authentification Hugging Face. Remplace l'ancien service DynaPictures.

Auteur: Assistant IA
Date: 2024
"""

import os
import logging
import torch
from typing import Dict, Optional, Any
from datetime import datetime
from diffusers import DiffusionPipeline
from huggingface_hub import login
from PIL import Image
import re

logger = logging.getLogger(__name__)

class DynaPicturesService:
    """
    Service de g√©n√©ration d'images avec Stable Diffusion v1.5.
    
    Utilise le mod√®le Stable Diffusion v1.5 de RunwayML pour g√©n√©rer
    des images de cocktails bas√©es sur les descriptions et prompts fournis.
    N√©cessite une authentification Hugging Face valide.
    """
    
    def __init__(self):
        """
        Initialise le service Stable Diffusion avec authentification Hugging Face.
        
        """
        self.hf_token = os.getenv('HUGGINGFACE_TOKEN')
        if not self.hf_token or self.hf_token == '<VOTRE-TOKEN-HUGGINGFACE>':
            raise ValueError(
                "HUGGINGFACE_TOKEN non configur√©. "
                "Veuillez d√©finir cette variable d'environnement avec votre token Hugging Face. "
                "G√©n√©rez un token sur https://huggingface.co/settings/tokens"
            )
        
        self.pipe = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        # Utilisation d'un mod√®le accessible sans restriction
        self.model_id = "runwayml/stable-diffusion-v1-5"
        
        # Authentification Hugging Face
        try:
            login(token=self.hf_token)
            logger.info("‚úÖ Connexion r√©ussie √† Hugging Face !")
        except Exception as e:
            logger.error(f"‚ùå Erreur d'authentification Hugging Face: {e}")
            raise ValueError(f"Authentification Hugging Face √©chou√©e: {e}")
        
        # Initialisation du pipeline (lazy loading)
        self._initialize_pipeline()
    
    def _initialize_pipeline(self):
        """
        Initialise le pipeline Stable Diffusion 3.5 Large.
        
        Utilise le lazy loading pour √©viter de charger le mod√®le si non n√©cessaire.
        Configure automatiquement le device (CUDA si disponible, sinon CPU).
        """
        try:
            logger.info(f"üîÑ Initialisation du pipeline Stable Diffusion v1.5 sur {self.device}...")
            
            # Configuration optimis√©e selon le device
            if self.device == "cuda":
                self.pipe = DiffusionPipeline.from_pretrained(
                    self.model_id,
                    torch_dtype=torch.float16,
                    use_safetensors=True
                ).to(self.device)
                
                # Optimisations CUDA
                self.pipe.enable_model_cpu_offload()
                self.pipe.enable_attention_slicing()
            else:
                logger.warning("‚ö†Ô∏è CUDA non disponible, utilisation du CPU (plus lent)")
                self.pipe = DiffusionPipeline.from_pretrained(
                    self.model_id,
                    torch_dtype=torch.float32
                ).to(self.device)
            
            logger.info("‚úÖ Pipeline Stable Diffusion initialis√© avec succ√®s")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'initialisation du pipeline: {e}")
            raise RuntimeError(f"Impossible d'initialiser Stable Diffusion: {e}")
    
    def _build_cocktail_prompt(self, cocktail_data: Dict[str, Any]) -> str:
        """
        Construit un prompt optimis√© pour la g√©n√©ration d'image de cocktail.
        
        Args:
            cocktail_data: Donn√©es du cocktail contenant nom, ingr√©dients, description
        
        Returns:
            str: Prompt optimis√© pour Stable Diffusion
        """
        cocktail_name = cocktail_data.get('name', 'Cocktail')
        ingredients = cocktail_data.get('ingredients', [])
        description = cocktail_data.get('description', '')
        image_prompt = cocktail_data.get('image_prompt', '')
        
        # Construction d'un prompt court et optimis√© (ignorer l'image_prompt long)
        color_hints = self._extract_color_hints(ingredients, description)
        style_hints = self._extract_style_hints(cocktail_name, description)
        
        # Prompt de base tr√®s concis
        base_prompt = f"Beautiful {cocktail_name} cocktail, elegant glass, {color_hints}, {style_hints}"
        
        # Limitation stricte √† 40 mots pour √©viter compl√®tement la troncature CLIP
        words = base_prompt.split()
        if len(words) > 35:  # Garde de la place pour les qualificatifs finaux
            base_prompt = ' '.join(words[:35])
        
        # Ajout de qualificatifs tr√®s courts
        enhanced_prompt = f"{base_prompt}, high quality, professional"
        
        # V√©rification finale - maximum 40 mots
        final_words = enhanced_prompt.split()
        if len(final_words) > 40:
            enhanced_prompt = ' '.join(final_words[:40])
        
        logger.info(f"üé® Prompt g√©n√©r√© ({len(enhanced_prompt.split())} mots): {enhanced_prompt[:100]}...")
        return enhanced_prompt
    
    def _extract_color_hints(self, ingredients: list, description: str) -> str:
        """
        Extrait des indices de couleur bas√©s sur les ingr√©dients et la description.
        
        Args:
            ingredients: Liste des ingr√©dients du cocktail
            description: Description textuelle du cocktail
        
        Returns:
            str: Indices de couleur pour le prompt
        """
        color_map = {
            'rhum': 'golden amber',
            'whisky': 'deep amber',
            'vodka': 'crystal clear',
            'gin': 'clear with botanical hints',
            'tequila': 'pale gold',
            'grenadine': 'ruby red gradient',
            'blue': 'vibrant blue',
            'rouge': 'deep red',
            'vert': 'emerald green',
            'citron': 'bright yellow',
            'orange': 'sunset orange',
            'cranberry': 'deep crimson',
            'passion': 'tropical orange'
        }
        
        colors = []
        text_to_analyze = ' '.join(ingredients).lower() + ' ' + description.lower()
        
        for ingredient, color in color_map.items():
            if ingredient in text_to_analyze:
                colors.append(color)
        
        if colors:
            return f"with {', '.join(colors[:2])} tones"
        return "with elegant color palette"
    
    def _extract_style_hints(self, name: str, description: str) -> str:
        """
        Extrait des indices de style bas√©s sur le nom et la description.
        
        Args:
            name: Nom du cocktail
            description: Description du cocktail
        
        Returns:
            str: Indices de style pour le prompt
        """
        style_keywords = {
            'tropical': 'tropical paradise setting with palm leaves',
            'summer': 'bright summer atmosphere',
            'winter': 'cozy winter ambiance',
            'elegant': 'sophisticated upscale bar',
            'vintage': 'classic vintage style',
            'modern': 'contemporary minimalist design',
            'exotic': 'exotic luxurious presentation',
            'classic': 'timeless classic cocktail style'
        }
        
        text_to_analyze = (name + ' ' + description).lower()
        
        for keyword, style in style_keywords.items():
            if keyword in text_to_analyze:
                return style
        
        return "elegant bar atmosphere"
    
    def _sanitize_filename(self, cocktail_name: str) -> str:
        """
        Nettoie le nom du cocktail pour cr√©er un nom de fichier valide.
        
        Args:
            cocktail_name: Nom original du cocktail
        
        Returns:
            str: Nom de fichier s√©curis√©
        """
        # Remplacer les caract√®res sp√©ciaux et espaces
        clean_name = re.sub(r'[^a-zA-Z0-9\s]', '', cocktail_name)
        clean_name = re.sub(r'\s+', '_', clean_name.strip())
        clean_name = clean_name.lower()
        
        # Limiter la longueur
        if len(clean_name) > 30:
            clean_name = clean_name[:30]
        
        return clean_name or 'cocktail'
    
    def generate_cocktail_image(self, cocktail_data: Dict[str, Any]) -> Optional[str]:
        """
        G√©n√®re une image de cocktail en utilisant Stable Diffusion 3.5 Large.
        
        Args:
            cocktail_data: Dictionnaire contenant les donn√©es du cocktail
                          (name, ingredients, description, image_prompt)
        
        Returns:
            Optional[str]: Chemin relatif vers l'image g√©n√©r√©e, ou None en cas d'erreur
        """
        try:
            # V√©rification de l'√©tat du pipeline
            if not self.pipe:
                logger.error("‚ùå Pipeline Stable Diffusion non initialis√©")
                return None
                
            # V√©rification que le pipeline est sur le bon device
            if hasattr(self.pipe, 'device') and self.pipe.device != self.device:
                logger.warning(f"‚ö†Ô∏è Pipeline sur device {self.pipe.device}, attendu {self.device}")
            
            cocktail_name = cocktail_data.get('name', 'Cocktail Inconnu')
            logger.info(f"üé® G√©n√©ration d'image pour le cocktail: {cocktail_name}")
            
            # Construction du prompt optimis√©
            prompt = self._build_cocktail_prompt(cocktail_data)
            
            # G√©n√©ration de l'image
            logger.info("üîÑ G√©n√©ration en cours avec Stable Diffusion 3.5 Large...")
            
            # Param√®tres ultra-conservateurs pour √©viter les erreurs
            generation_params = {
                "prompt": prompt,
                "num_inference_steps": 15,  # Encore plus r√©duit
                "guidance_scale": 7.0,      # Valeur standard
                "width": 512,
                "height": 512,
                "negative_prompt": "blurry, low quality, distorted",  # Am√©liore la qualit√©
                "num_images_per_prompt": 1  # Explicitement une seule image
            }
            
            # Pas de generator pour √©viter les erreurs d'index
            # Le mod√®le utilisera sa propre graine al√©atoire
            
            # G√©n√©ration avec gestion d'erreur robuste
            result = self.pipe(**generation_params)
            
            # V√©rification que le r√©sultat contient des images
            if not hasattr(result, 'images') or not result.images:
                logger.error("‚ùå Aucune image g√©n√©r√©e par le pipeline")
                return None
                
            image = result.images[0]
            
            # V√©rification que l'image est valide
            if image is None:
                logger.error("‚ùå Image g√©n√©r√©e est None")
                return None
            
            # Sauvegarde de l'image
            filename = self._save_image(image, cocktail_name)
            if filename:
                logger.info(f"‚úÖ Image g√©n√©r√©e et sauvegard√©e: {filename}")
                return filename
            else:
                logger.error("‚ùå Erreur lors de la sauvegarde de l'image")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la g√©n√©ration d'image: {e}")
            return None
    
    def _save_image(self, image: Image.Image, cocktail_name: str) -> Optional[str]:
        """
        Sauvegarde l'image g√©n√©r√©e dans le dossier public du frontend.
        
        Args:
            image: Image PIL g√©n√©r√©e
            cocktail_name: Nom du cocktail pour le nom de fichier
        
        Returns:
            Optional[str]: Chemin relatif vers l'image sauvegard√©e
        """
        try:
            # Cr√©ation du nom de fichier unique
            clean_name = self._sanitize_filename(cocktail_name)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"cocktail_{clean_name}_{timestamp}.png"
            
            # Chemin vers le dossier public du frontend
            frontend_public_dir = os.path.join(
                os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
                'frontend', 'public'
            )
            
            # Cr√©er le dossier s'il n'existe pas
            os.makedirs(frontend_public_dir, exist_ok=True)
            
            # Chemin complet du fichier
            file_path = os.path.join(frontend_public_dir, filename)
            
            # Sauvegarde avec optimisation
            image.save(file_path, "PNG", optimize=True, quality=95)
            
            # Retourner le chemin relatif pour l'URL
            relative_path = f"/{filename}"
            logger.info(f"üíæ Image sauvegard√©e: {file_path}")
            
            return relative_path
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la sauvegarde: {e}")
            return None
    
    def test_connection(self) -> bool:
        """
        Teste la connexion et la fonctionnalit√© du service Stable Diffusion.
        
        Returns:
            bool: True si le service fonctionne correctement
        """
        try:
            logger.info("üß™ Test de connexion Stable Diffusion...")
            
            if not self.pipe:
                logger.error("‚ùå Pipeline non initialis√©")
                return False
            
            # Test avec un prompt simple
            test_prompt = "A simple elegant cocktail glass, professional photography"
            
            # G√©n√©ration de test avec param√®tres r√©duits pour la rapidit√©
            result = self.pipe(
                prompt=test_prompt,
                num_inference_steps=10,  # R√©duit pour le test
                guidance_scale=7.5,
                width=512,               # R√©solution r√©duite pour le test
                height=512
            )
            
            if result and result.images and len(result.images) > 0:
                logger.info("‚úÖ Test de g√©n√©ration Stable Diffusion r√©ussi")
                return True
            else:
                logger.error("‚ùå Test de g√©n√©ration √©chou√©: aucune image g√©n√©r√©e")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Test de connexion √©chou√©: {e}")
            return False
    
    def get_service_info(self) -> Dict[str, Any]:
        """
        Retourne les informations sur le service de g√©n√©ration d'images.
        
        Returns:
            Dict[str, Any]: Informations sur le service
        """
        return {
            "service_name": "Stable Diffusion 3.5 Large",
            "model_id": self.model_id,
            "device": self.device,
            "cuda_available": torch.cuda.is_available(),
            "pipeline_loaded": self.pipe is not None,
            "hf_authenticated": bool(self.hf_token and self.hf_token != '<VOTRE-TOKEN-HUGGINGFACE>')
        }